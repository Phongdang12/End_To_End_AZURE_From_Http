ğŸš€ Azure Data Pipeline Project â€“ From API to Insights
ğŸ” Overview
This project demonstrates a complete modern data pipeline that extracts raw data from external APIs, ingests it into Azure Data Lake Storage Gen2, and transforms it using Azure Databricks for advanced analytics and reporting.

ğŸ”— Built on Azure Cloud Services, this pipeline ensures scalable, secure, and cost-efficient data processing with a clear separation of data layers (Bronze, Silver, Gold) using the Medallion architecture.

ğŸ“Š Architecture
[External API] 
     â†“
[Azure Data Factory / Azure Function]
     â†“
[Azure Data Lake Storage Gen2 (Bronze)]
     â†“
[Azure Databricks Notebook â€“ ETL Processing]
     â†“
[Delta Lake â€“ Silver & Gold Layers]
     â†“
[Power BI / Azure Synapse Analytics (Optional)]
ğŸ§± Components
Component	Description
ğŸ”— API Connector	Connects and extracts raw data from RESTful API endpoints.
ğŸ’¾ Azure Data Lake Gen2	Stores raw (Bronze), cleaned (Silver), and aggregated (Gold) data.
ğŸ§  Azure Databricks	Transforms and cleans data using PySpark in scalable notebooks.
ğŸ§° Delta Lake	Enables ACID transactions, schema enforcement, and time travel.
ğŸ“ˆ (Optional) Power BI	Connects to Gold layer for dynamic dashboards and visualizations.



ğŸš¦ Data Layering Strategy (Medallion Architecture)
Bronze â€“ Raw data ingested from the API (no transformation).

Silver â€“ Cleaned and validated data, with proper schema and formatting.

Gold â€“ Business-ready datasets, aggregated or joined as needed.


âœ¨ Authors
ğŸ“§ Your Name â€“ phong.danghandsomek@hcmut.edu.vn

ğŸ§  Feel free to fork, improve, and contribute!

